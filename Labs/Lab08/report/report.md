---
# Front matter
lang: ru-RU
title: "Основы информационной безопасности"
subtitle: "Лабораторная работа № 8. Элементы криптографии. Шифрование (кодирование) различных исходных текстов одним ключом"

author: "Нзита Диатезилуа Катенди"

# Formatting
toc-title: "Содержание"
toc: true # Table of contents
toc_depth: 2
lof: true # List of figures
fontsize: 12pt
linestretch: 1.5
papersize: a4paper
documentclass: scrreprt
polyglossia-lang: russian
polyglossia-otherlangs: english
mainfont: PT Serif
romanfont: PT Serif
sansfont: PT Sans
monofont: PT Mono
mainfontoptions: Ligatures=TeX
romanfontoptions: Ligatures=TeX
sansfontoptions: Ligatures=TeX,Scale=MatchLowercase
monofontoptions: Scale=MatchLowercase
indent: true
pdf-engine: lualatex
header-includes:
  - \linepenalty=10 # the penalty added to the badness of each line within a paragraph (no associated penalty node) Increasing the υalue makes tex try to haυe fewer lines in the paragraph.
  - \interlinepenalty=0 # υalue of the penalty (node) added after each line of a paragraph.
  - \hyphenpenalty=50 # the penalty for line breaking at an automatically inserted hyphen
  - \exhyphenpenalty=50 # the penalty for line breaking at an explicit hyphen
  - \binoppenalty=700 # the penalty for breaking a line at a binary operator
  - \relpenalty=500 # the penalty for breaking a line at a relation
  - \clubpenalty=150 # extra penalty for breaking after first line of a paragraph
  - \widowpenalty=150 # extra penalty for breaking before last line of a paragraph
  - \displaywidowpenalty=50 # extra penalty for breaking before last line before a display math
  - \brokenpenalty=100 # extra penalty for page breaking after a hyphenated line
  - \predisplaypenalty=10000 # penalty for breaking before a display
  - \postdisplaypenalty=0 # penalty for breaking after a display
  - \floatingpenalty = 20000 # penalty for splitting an insertion (can only be split footnote in standard LaTeX)
  - \raggedbottom # or \flushbottom
  - \usepackage{float} # keep figures where there are in the text
  - \floatplacement{figure}{H} # keep figures where there are in the text
---

# Цель работы

Освоить на практике применение режима однократного гаммирования на примере кодирования различных исходных текстов одним ключом.

# Задание 

Два текста кодируются одним ключом (однократное гаммирование). Требуется не зная ключа и не стремясь его определить, прочитать оба текста. Необходимо разработать приложение, позволяющее шифровать и дешифровать тексты P1 и P2 в режиме однократного гаммирования. Приложение должно определить вид шифротекстов C1 и C2 обоих текстов P1 и P2 при известном ключе ; Необходимо определить и выразить аналитически способ, при котором злоумышленник может прочитать оба текста, не зная ключа и не стремясь его определить

# Теоретические сведения

В результате выполнения работы были освоены практические навыки применения режима однократного гаммирования на примере кодирования различных исходных текстов одним ключом

# Выполнение лабораторной работы

# Часть 1. Методы безусловной оптимизации

1. **Постановка задачи оптимизации. Классификация задач оптимизации.**
   - Задача оптимизации заключается в нахождении максимума или минимума функции \( f(x) \) при определенных условиях. 
   - Классификация:
     - **Безусловная оптимизация:** не имеет ограничений.
     - **Условная оптимизация:** включает ограничения.

2. **Понятие экстремума. Точки глобального минимума и максимума. Минимизирующая последовательность. Точки локального минимума и максимума. Двойственность задач минимизации и максимизации функции.**
   - Экстремум функции \( f(x) \) — это точка \( x^* \), где \( f(x^*) \) является наибольшим или наименьшим значением.
   - **Глобальный минимум/максимум:** \( f(x^*) \leq f(x) \) для всех \( x \).
   - **Локальный минимум/максимум:** \( f(x^*) \leq f(x) \) для \( x \) в некоторой окрестности точки \( x^* \).
   - Минимизирующая последовательность: последовательность \( x_n \) такая, что \( f(x_n) \) сходится к \( \min f(x) \).
   - Двойственность: задачи минимизации и максимизации связаны через двойственные функции.

3. **Две разновидности задач оптимизации. Теорема Вейерштрасса.**
   - **Разновидности:**
     - **Линейные задачи:** целевая функция и ограничения линейные.
     - **Нелинейные задачи:** хотя бы одна функция нелинейна.
   - Теорема Вейерштрасса: если \( f(x) \) непрерывна на замкнутом и ограниченном множестве \( D \), то \( f \) достигает максимума и минимума на \( D \).

4. **Постановка задачи безусловной оптимизации. Необходимое условие экстремума первого порядка. Стационарные точки. Необходимые и достаточные условия второго порядка.**
   - Задача:
     \[
     \min f(x)
     \]
   - Необходимое условие:
     \[
     \nabla f(x^*) = 0
     \]
   - Стационарные точки: точки, где градиент равен нулю.
   - Условия второго порядка:
     \[
     H_f(x^*) \succ 0 \quad (\text{для минимума}) 
     \]
     \[
     H_f(x^*) \prec 0 \quad (\text{для максимума}) 
     \]
     где \( H_f \) — матрица Гессе.

5. **Понятия выпуклых и вогнутых функций. Унимодальные функции.**
   - **Выпуклая функция:** \( f(\lambda x_1 + (1-\lambda)x_2) \leq \lambda f(x_1) + (1-\lambda)f(x_2) \) для \( \lambda \in [0, 1] \).
   - **Вогнутая функция:** обратное неравенство.
   - **Унимодальная функция:** имеет один экстремум.

6. **Численные методы безусловной минимизации первого порядка. Общая схема построения минимизирующей последовательности.**
   - Схема:
     1. Инициализация \( x_0 \).
     2. Для \( n = 0, 1, \ldots \):
        \[
        x_{n+1} = x_n - \alpha \nabla f(x_n)
        \]
     3. \( \alpha \) — шаг.

7. **Метод градиентного спуска. Алгоритм метода и условия сходимости.**
   - Алгоритм:
     1. Инициализация \( x_0 \).
     2. Для \( n = 0, 1, \ldots \):
        \[
        x_{n+1} = x_n - \alpha \nabla f(x_n)
        \]
   - Условия сходимости: шаг \( \alpha \) должен быть достаточно малым и положительным.

8. **Метод наискорейшего спуска. Алгоритм метода и условия сходимости.**
   - Алгоритм:
     1. Инициализация \( x_0 \).
     2. Для \( n = 0, 1, \ldots \):
        \[
        x_{n+1} = x_n - \alpha_n \nabla f(x_n)
        \]
     3. Шаг определяется минимизацией \( f(x_n - \alpha \nabla f(x_n)) \).
   - Условия сходимости: \( \alpha_n \) должен быть положительным.

9. **Метод покоординатного спуска. Алгоритм метода и условия сходимости.**
   - Алгоритм:
     1. Инициализация \( x_0 \).
     2. Для \( n = 0, 1, \ldots \):
        \[
        x_{n+1}^i = \arg\min_{x^i} f(x^1, \ldots, x^i, \ldots, x^n)
        \]
   - Условия сходимости: \( f(x) \) должен быть непрерывным и выпуклым.

10. **Метод Гаусса-Зейделя. Алгоритм метода и условия сходимости.**
    - Алгоритм:
      1. Инициализация \( x_0 \).
      2. Для \( n = 0, 1, \ldots \):
         \[
         x_{n+1}^i = \frac{b_i - \sum_{j=1}^{i-1} a_{ij} x_{n+1}^j - \sum_{j=i+1}^{n} a_{ij} x_n^j}{a_{ii}}
         \]
    - Условия сходимости: матрица \( A \) должна быть строгой диагонально- dominante.

11. **Методы сопряженных градиентов. Идея метода. Методы Флетчера-Ривса и Поляка-Рибьера. Алгоритмы методов и условия сходимости.**
    - Идея: использование градиента для нахождения следующей точки.
    - Метод Флетчера-Ривса:
      \[
      x_{n+1} = x_n - \alpha_n p_n
      \]
    - Метод Поляка-Рибьера:
      \[
      p_{n+1} = -\nabla f(x_{n+1}) + \beta_n p_n
      \]
    - Условия сходимости: функция должна быть выпуклой.

12. **Численные методы безусловной минимизации второго порядка. Общая схема построения минимизирующей последовательности.**
    - Схема:
      1. Инициализация \( x_0 \).
      2. Для \( n = 0, 1, \ldots \):
         \[
         x_{n+1} = x_n - H_f(x_n)^{-1} \nabla f(x_n)
         \]

13. **Метод Ньютона и Ньютона-Рафсона. Алгоритмы методов и условия сходимости.**
    - Метод Ньютона:
      \[
      x_{n+1} = x_n - H_f(x_n)^{-1} \nabla f(x_n)
      \]
    - Метод Ньютона-Рафсона:
      \[
      x_{n+1} = x_n - \frac{f'(x_n)}{f''(x_n)}
      \]
    - Условия сходимости: если \( f \) дважды непрерывно дифференцируема.

14. **Метод секущих. Алгоритм метода и условия сходимости.**
    - Алгоритм:
      1. Инициализация \( x_0, x_1 \).
      2. Для \( n = 0, 1, \ldots \):
         \[
         x_{n+2} = x_{n+1} - f(x_{n+1}) \frac{x_{n+1} - x_n}{f(x_{n+1}) - f(x_n)}
         \]
    - Условия сходимости: для непрерывных функций.

15. **Метод простых итераций. Общая схема построения минимизирующей последовательности.**
    - Схема:
      1. Инициализация \( x_0 \).
      2. Для \( n = 0, 1, \ldots \):
         \[
         x_{n+1} = g(x_n)
         \]
      3. Условия сходимости: функция \( g \) должна быть сжимающей.

16. **Метод проекции. Общая схема построения минимизирующей последовательности.**
    - Схема:
      1. Инициализация \( x_0 \).
      2. Для \( n = 0, 1, \ldots \):
         \[
         x_{n+1} = P_{C}(x_n - \alpha \nabla f(x_n))
         \]
      3. \( P_{C} \) — проекция на множество \( C \).

17. **Численные методы безусловной минимизации нулевого порядка. Одномерный случай. Методы равномерного поиска и деления отрезка пополам. Алгоритмы методов и условия сходимости.**
    - Методы:
      1. **Равномерный поиск:** исследование значений на равномерной сетке.
      2. **Деление отрезка пополам:**
         \[
         x_{n+1} = \frac{a + b}{2}
         \]
      3. Условия сходимости: функция должна быть непрерывной.

18. **Метод конфигураций. Алгоритм метода и условия сходимости.**
    - Алгоритм:
      1. Инициализация конфигурации.
      2. Для \( n = 0, 1, \ldots \):
         \[
         \text{Перемещение по конфигурации для нахождения минимума.}
         \]
    - Условия сходимости: количество шагов и размеры шага.

19. **Метод деформируемого многогранника. Алгоритм метода и условия сходимости.**
    - Алгоритм:
      1. Инициализация многогранника.
      2. Для \( n = 0, 1, \ldots \):
         \[
         \text{Деформация многогранника для нахождения минимума.}
         \]
    - Условия сходимости: функция должна быть выпуклой.

# Часть 2. Методы условной оптимизации

20. **Постановка задачи условной оптимизации с ограничениями типа равенств. Регулярный и нерегулярный экстремум. Обобщенная и классическая функция Лагранжа.**
    - Задача:
      \[
      \min f(x) \quad \text{при } g(x) = 0
      \]
    - Регулярный экстремум: функции \( g(x) \) линейно независимы.
    - Обобщенная функция Лагранжа:
      \[
      L(x, \lambda) = f(x) + \lambda g(x)
      \]

21. **Необходимые условия условного экстремума первого порядка для задач оптимизации с ограничениями типа равенств. Понятие условно стационарной точки. Геометрическая иллюстрация.**
    - Необходимые условия:
      \[
      \nabla f(x^*) + \lambda \nabla g(x^*) = 0
      \]
    - Условно стационарная точка: точка, где градиент функции равен нулю с учетом ограничений.

22. **Необходимые и достаточные условия условного экстремума второго порядка для задач оптимизации с ограничениями типа равенств.**
    - Необходимые условия второго порядка:
      \[
      H_f(x^*) \succ 0 \quad \text{и} \quad \nabla g(x^*)^T H_f(x^*) \nabla g(x^*) = 0
      \]
    - Достаточные условия: если \( H_L(x^*) \) положительно определена.

23. **Экономическая интерпретация множителей Лагранжа.**
    - Множитель Лагранжа \( \lambda \) представляет собой изменение целевой функции при малом изменении ограничения.

24. **Постановка задачи условной оптимизации с ограничениями типа неравенств. Регулярный и нерегулярный экстремум. Обобщенная и классическая функция Лагранжа. Активные и пассивные ограничения.**
    - Задача:
      \[
      \min f(x) \quad \text{при } g(x) \leq 0
      \]
    - Регулярный экстремум: активные ограничения определяют оптимум.
    - Обобщенная функция Лагранжа:
      \[
      L(x, \lambda) = f(x) + \sum_{i} \lambda_i g_i(x)
      \]

25. **Необходимые условия условного экстремума первого порядка для задач оптимизации с ограничениями типа неравенств. Понятие условно стационарной точки. Геометрическая иллюстрация.**
    - Необходимые условия:
      \[
      \nabla f(x^*) + \sum_{i} \lambda_i \nabla g_i(x^*) = 0
      \]
    - Условно стационарная точка: аналогично, но с учетом активных ограничений.

26. **Достаточные условия первого порядка, необходимые и достаточные условия условного экстремума второго порядка для задач оптимизации с ограничениями типа неравенств.**
    - Достаточные условия первого порядка:
      \[
      g_i(x^*) \leq 0, \lambda_i \geq 0, \lambda_i g_i(x^*) = 0
      \]
    - Необходимые и достаточные условия второго порядка аналогично условиям для равенств.

# Часть 3. Основы вариационного исчисления

27. **Постановка вариационной задачи. Понятие функционала. Понятие допустимой кривой. Задача Дидоны. Задача о брахистохроне.**
    - Вариационная задача: нахождение функции \( y(x) \), минимизирующей функционал \( J[y] \).
    - Допустимая кривая: \( y(x) \) удовлетворяет условиям задачи.
    - Задача Дидоны:
      \[
      J[y] = \int_a^b L(y, y', x) \, dx
      \]
    - Задача о брахистохроне: минимизация времени падения.

28. **Понятие нормы в пространствах непрерывных и непрерывно дифференцируемых кривых. Понятие окрестности кривой. Понятие глобального экстремума функционала. Экстремали. Сильный и слабый экстремум функционала.**
    - Норма:
      \[
      \|y\| = \int_a^b |y(x)|^2 \, dx
      \]
    - Глобальный экстремум: минимум/максимум функционала по всем допустимым кривым.
    - Экстремали: функции, которые дают минимум/максимум функционала.

29. **Понятие вариации кривой и функционала. Представление допустимой кривой через экстремаль и вариацию кривой.**
    - Вариация:
      \[
      \delta J = J[y + \delta y] - J[y]
      \]
    - Допустимая кривая \( y(x) \) представляется через экстремаль и вариацию: 
      \[
      J[y] \text{ имеет экстремум, если } \delta J = 0
      \]

30. **Уравнение Эйлера-Лагранжа. Необходимые и достаточные условия экстремума функционала.**
    - Уравнение Эйлера-Лагранжа:
      \[
      \frac{\partial F}{\partial y} - \frac{d}{dx} \left( \frac{\partial F}{\partial y'} \right) = 0
      \]
    - Необходимые условия:
      1. \( J[y] \) должен иметь вариацию ноль: \( \delta J = 0 \).
      2. Для экстремума должен выполниться закон.


# Часть 4. Простейшие вариационные задачи

30. **Простейшая вариационная задача от одной функции с закрепленными концами. Необходимое условие экстремума функционала второго порядка. Условие Лежандра.**
    - Простейшая вариационная задача:
      \[
      J[y] = \int_a^b F(y, y', x) \, dx
      \]
    - Необходимое условие экстремума второго порядка:
      - Если \( y^* \) — экстремаль, то
      \[
      \delta J = 0
      \]
      - Условие Лежандра:
      \[
      \frac{\partial^2 F}{\partial y'^2} \geq 0
      \]

31. **Простейшая вариационная задача от одной функции с закрепленными концами. Необходимое условие экстремума функционала. Условие Якоби. Условие Вейерштрасса.**
    - Необходимое условие экстремума:
      \[
      \frac{\partial F}{\partial y} - \frac{d}{dx} \left( \frac{\partial F}{\partial y'} \right) = 0
      \]
    - Условие Якоби:
      - Функция \( F(y, y', x) \) должна быть непрерывной и дифференцируемой.
    - Условие Вейерштрасса:
      - Для всякой допустимой кривой, если \( y_a \) и \( y_b \) фиксированы, тогда
      \[
      J[y] \geq J[y^*]
      \]

32. **Простейшая вариационная задача от одной функции с закрепленными концами. Достаточное условие сильного и слабого экстремума функционала.**
    - Достаточные условия:
      - Сильный экстремум:
      \[
      \frac{\partial^2 F}{\partial y'^2} > 0
      \]
      - Слабый экстремум:
      \[
      \frac{\partial^2 F}{\partial y'^2} \geq 0
      \]

33. **Простейшая вариационная задача от нескольких функций с закрепленными концами. Необходимое условие экстремума. Уравнение Эйлера. Дифференцируемость экстремалей.**
    - Задача:
      \[
      J[y_1, y_2, \ldots, y_n] = \int_a^b F(y_1, y_2, \ldots, y_n, y'_1, y'_2, \ldots, y'_n, x) \, dx
      \]
    - Необходимое условие экстремума:
      \[
      \frac{\partial F}{\partial y_i} - \frac{d}{dx} \left( \frac{\partial F}{\partial y'_i} \right) = 0, \quad i = 1, 2, \ldots, n
      \]
    - Дифференцируемость экстремалей: все функции \( y_i \) должны быть дифференцируемыми.

34. **Простейшая вариационная задача от нескольких функций с закрепленными концами. Необходимое условие экстремума функционала второго порядка. Условие Лежандра.**
    - Необходимое условие второго порядка:
      \[
      \delta J = 0
      \]
    - Условие Лежандра:
      \[
      \frac{\partial^2 F}{\partial y'_i \partial y'_j} \geq 0 \quad \text{для } i, j = 1, 2, \ldots, n
      \]

35. **Простейшая вариационная задача от нескольких функций с закрепленными концами. Необходимое условие экстремума функционала. Условие Якоби. Условие Вейерштрасса.**
    - Необходимое условие:
      \[
      \frac{\partial F}{\partial y_i} - \frac{d}{dx} \left( \frac{\partial F}{\partial y'_i} \right) = 0
      \]
    - Условие Якоби:
      - \( F \) должна быть непрерывной и дифференцируемой.
    - Условие Вейерштрасса:
      - Для всех допустимых функций \( y_i \):
      \[
      J[y_1, y_2, \ldots, y_n] \geq J[y_1^*, y_2^*, \ldots, y_n^*]
      \]

36. **Простейшая вариационная задача от нескольких функций с закрепленными концами. Достаточное условие сильного и слабого экстремума функционала.**
    - Достаточные условия:
      - Сильный экстремум:
      \[
      \frac{\partial^2 F}{\partial y'_i \partial y'_j} > 0
      \]
      - Слабый экстремум:
      \[
      \frac{\partial^2 F}{\partial y'_i \partial y'_j} \geq 0
      \]

37. **Простейшая вариационная задача от одной функции со свободным концом. Условия трансверсальности.**
    - Задача:
      \[
      J[y] = \int_a^b F(y, y', x) \, dx
      \]
    - Условия трансверсальности:
      - Если один из концов свободен, то
      \[
      \frac{\partial F}{\partial y'}(y(a), y'(a), a) = 0 \quad \text{или} \quad \frac{\partial F}{\partial y'}(y(b), y'(b), b) = 0
      \]


# Список литературы{.unnumbered}

::: {#refs}
:::


